{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-07T04:42:00.324987Z","iopub.execute_input":"2023-11-07T04:42:00.325277Z","iopub.status.idle":"2023-11-07T04:42:00.686413Z","shell.execute_reply.started":"2023-11-07T04:42:00.325251Z","shell.execute_reply":"2023-11-07T04:42:00.685358Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:42:00.687980Z","iopub.execute_input":"2023-11-07T04:42:00.688384Z","iopub.status.idle":"2023-11-07T04:42:13.510344Z","shell.execute_reply.started":"2023-11-07T04:42:00.688356Z","shell.execute_reply":"2023-11-07T04:42:13.509249Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nimport tensorflow as tf\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:43:47.147157Z","iopub.execute_input":"2023-11-07T04:43:47.148166Z","iopub.status.idle":"2023-11-07T04:43:47.636555Z","shell.execute_reply.started":"2023-11-07T04:43:47.148121Z","shell.execute_reply":"2023-11-07T04:43:47.635521Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Download stopwords if not already downloaded\nnltk.download(\"stopwords\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:45:38.049733Z","iopub.execute_input":"2023-11-07T04:45:38.050603Z","iopub.status.idle":"2023-11-07T04:45:38.119611Z","shell.execute_reply.started":"2023-11-07T04:45:38.050573Z","shell.execute_reply":"2023-11-07T04:45:38.118596Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/dataset/dataset.csv', encoding = 'latin-1', header = None)\ndata = data.rename(columns = {0:'Sentiment', 1:'id',2:'datetime',3:'query',4:'user',5:'Text'})\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:45:20.487224Z","iopub.execute_input":"2023-11-07T04:45:20.487933Z","iopub.status.idle":"2023-11-07T04:45:28.816098Z","shell.execute_reply.started":"2023-11-07T04:45:20.487898Z","shell.execute_reply":"2023-11-07T04:45:28.815035Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(1600000, 6)"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocess the data\ndata[\"Sentiment\"] = data[\"Sentiment\"].map({0: 0, 2: 1, 4: 2})","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:45:54.734707Z","iopub.execute_input":"2023-11-07T04:45:54.735600Z","iopub.status.idle":"2023-11-07T04:45:54.766122Z","shell.execute_reply.started":"2023-11-07T04:45:54.735569Z","shell.execute_reply":"2023-11-07T04:45:54.765284Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define a function for text preprocessing\ndef preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n\n    # Remove special characters, punctuation, and numbers\n    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n\n    # Tokenize the text\n    words = text.split()\n\n    # Remove common stopwords\n    stop_words = set(stopwords.words(\"english\"))\n    words = [word for word in words if word not in stop_words]\n\n    # Join the words back into a single string\n    text = \" \".join(words)\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:46:07.315173Z","iopub.execute_input":"2023-11-07T04:46:07.315844Z","iopub.status.idle":"2023-11-07T04:46:07.321675Z","shell.execute_reply.started":"2023-11-07T04:46:07.315800Z","shell.execute_reply":"2023-11-07T04:46:07.320632Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Apply text preprocessing to each text in the dataset\ndata[\"Text\"] = data[\"Text\"].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:46:20.338898Z","iopub.execute_input":"2023-11-07T04:46:20.339236Z","iopub.status.idle":"2023-11-07T04:50:10.870342Z","shell.execute_reply.started":"2023-11-07T04:46:20.339211Z","shell.execute_reply":"2023-11-07T04:50:10.869404Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and testing sets\nX = data[\"Text\"]\ny = data[\"Sentiment\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:50:10.871996Z","iopub.execute_input":"2023-11-07T04:50:10.872289Z","iopub.status.idle":"2023-11-07T04:50:11.181446Z","shell.execute_reply.started":"2023-11-07T04:50:10.872264Z","shell.execute_reply":"2023-11-07T04:50:11.180412Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Load BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T04:43:06.521241Z","iopub.execute_input":"2023-11-07T04:43:06.521963Z","iopub.status.idle":"2023-11-07T04:43:17.843340Z","shell.execute_reply.started":"2023-11-07T04:43:06.521927Z","shell.execute_reply":"2023-11-07T04:43:17.842435Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db7f11d3ccdd4a7796f36f759c37c97d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7da0f3516f947b9b1b027bf37e45af4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"434a279d3c9c4026b4c62380ff08e36f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e304bd2095ca44e9a80301a23d20afab"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize and prepare the data\ntrain_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True, max_length=64, return_tensors='tf')\ntest_encodings = tokenizer(X_test.to_list(), truncation=True, padding=True, max_length=64, return_tensors='tf')","metadata":{"execution":{"iopub.status.busy":"2023-11-07T05:12:35.045951Z","iopub.execute_input":"2023-11-07T05:12:35.046752Z","iopub.status.idle":"2023-11-07T05:23:43.919433Z","shell.execute_reply.started":"2023-11-07T05:12:35.046708Z","shell.execute_reply":"2023-11-07T05:23:43.918369Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train.to_list()))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test.to_list()))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T05:23:43.921056Z","iopub.execute_input":"2023-11-07T05:23:43.921378Z","iopub.status.idle":"2023-11-07T05:23:48.436397Z","shell.execute_reply.started":"2023-11-07T05:23:43.921352Z","shell.execute_reply":"2023-11-07T05:23:48.435577Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Fine-tune the BERT model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-07T05:23:48.459939Z","iopub.execute_input":"2023-11-07T05:23:48.460216Z","iopub.status.idle":"2023-11-07T05:23:48.472293Z","shell.execute_reply.started":"2023-11-07T05:23:48.460192Z","shell.execute_reply":"2023-11-07T05:23:48.471508Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-07T05:23:49.103750Z","iopub.execute_input":"2023-11-07T05:23:49.104150Z","iopub.status.idle":"2023-11-07T05:23:49.139846Z","shell.execute_reply.started":"2023-11-07T05:23:49.104115Z","shell.execute_reply":"2023-11-07T05:23:49.138945Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bert (TFBertMainLayer)      multiple                  109482240 \n                                                                 \n dropout_37 (Dropout)        multiple                  0         \n                                                                 \n classifier (Dense)          multiple                  2307      \n                                                                 \n=================================================================\nTotal params: 109,484,547\nTrainable params: 109,484,547\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_dataset.shuffle(1000).batch(16), epochs=2, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T05:24:02.562515Z","iopub.execute_input":"2023-11-07T05:24:02.563350Z","iopub.status.idle":"2023-11-07T11:48:55.657215Z","shell.execute_reply.started":"2023-11-07T05:24:02.563315Z","shell.execute_reply":"2023-11-07T11:48:55.656002Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/2\n80000/80000 [==============================] - 11569s 144ms/step - loss: 0.4298 - accuracy: 0.7993\nEpoch 2/2\n80000/80000 [==============================] - 11523s 144ms/step - loss: 0.3747 - accuracy: 0.8309\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7c823b01c1f0>"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\nresults = model.evaluate(test_dataset.batch(16))\nprint(\"Test loss, Test accuracy:\", results)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T11:49:01.659277Z","iopub.execute_input":"2023-11-07T11:49:01.660072Z","iopub.status.idle":"2023-11-07T12:08:39.197258Z","shell.execute_reply.started":"2023-11-07T11:49:01.660035Z","shell.execute_reply":"2023-11-07T12:08:39.196232Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"20000/20000 [==============================] - 1178s 59ms/step - loss: 0.4146 - accuracy: 0.8151\nTest loss, Test accuracy: [0.4145992696285248, 0.8150812387466431]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert logits to predicted classes\ny_pred_logits = model.predict(test_dataset.batch(16))\ny_pred_classes = np.argmax(y_pred_logits.logits, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:45:20.002746Z","iopub.status.idle":"2023-11-07T12:45:20.003086Z","shell.execute_reply.started":"2023-11-07T12:45:20.002924Z","shell.execute_reply":"2023-11-07T12:45:20.002940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_classes","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:47:54.707253Z","iopub.execute_input":"2023-11-07T12:47:54.708001Z","iopub.status.idle":"2023-11-07T12:47:54.713977Z","shell.execute_reply.started":"2023-11-07T12:47:54.707967Z","shell.execute_reply":"2023-11-07T12:47:54.713076Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([0, 2, 2, ..., 2, 2, 0])"},"metadata":{}}]},{"cell_type":"code","source":"precision = precision_score(y_test, y_pred_classes, average='weighted')\nrecall = recall_score(y_test, y_pred_classes, average='weighted')\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\naccuracy = accuracy_score(y_test, y_pred_classes)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:45:24.137301Z","iopub.execute_input":"2023-11-07T12:45:24.138072Z","iopub.status.idle":"2023-11-07T12:45:24.525164Z","shell.execute_reply.started":"2023-11-07T12:45:24.138038Z","shell.execute_reply":"2023-11-07T12:45:24.524344Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1-Score: {f1}\")\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:45:28.166439Z","iopub.execute_input":"2023-11-07T12:45:28.167355Z","iopub.status.idle":"2023-11-07T12:45:28.172963Z","shell.execute_reply.started":"2023-11-07T12:45:28.167320Z","shell.execute_reply":"2023-11-07T12:45:28.171853Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Precision: 0.815138287834419\nRecall: 0.81508125\nF1-Score: 0.8150674314214681\nAccuracy: 0.81508125\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('/kaggle/working/saved_models/bert')","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:56:29.260110Z","iopub.execute_input":"2023-11-07T12:56:29.260543Z","iopub.status.idle":"2023-11-07T12:57:11.433479Z","shell.execute_reply.started":"2023-11-07T12:56:29.260510Z","shell.execute_reply":"2023-11-07T12:57:11.432594Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Replace 'folder_to_download' with the path to your folder\nfolder_path = '/saved_models'\nshutil.make_archive(\"/kaggle/working/saved_models/bert\", 'zip', folder_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:57:22.524131Z","iopub.execute_input":"2023-11-07T12:57:22.524530Z","iopub.status.idle":"2023-11-07T12:58:32.284141Z","shell.execute_reply.started":"2023-11-07T12:57:22.524497Z","shell.execute_reply":"2023-11-07T12:58:32.283145Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/saved_models/bert.zip'"},"metadata":{}}]},{"cell_type":"code","source":"# Apply text preprocessing to the input text\ninput_text = \"This is a bad product! I hate it.\"\npreprocessed_input = preprocess_text(input_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:54:50.923663Z","iopub.execute_input":"2023-11-07T12:54:50.924392Z","iopub.status.idle":"2023-11-07T12:54:50.929252Z","shell.execute_reply.started":"2023-11-07T12:54:50.924358Z","shell.execute_reply":"2023-11-07T12:54:50.928324Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Tokenize and prepare the input data\ninput_encodings = tokenizer(preprocessed_input, truncation=True, padding=True, max_length=64, return_tensors='tf')","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:54:52.679621Z","iopub.execute_input":"2023-11-07T12:54:52.680091Z","iopub.status.idle":"2023-11-07T12:54:52.686074Z","shell.execute_reply.started":"2023-11-07T12:54:52.680052Z","shell.execute_reply":"2023-11-07T12:54:52.684963Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Convert BatchEncoding to dictionary\ninput_dict = {key: input_encodings[key] for key in input_encodings}\n\n# Make a prediction\ninput_logits = model.predict(input_dict)\ninput_class = np.argmax(input_logits.logits, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:54:53.708544Z","iopub.execute_input":"2023-11-07T12:54:53.709405Z","iopub.status.idle":"2023-11-07T12:54:53.800369Z","shell.execute_reply.started":"2023-11-07T12:54:53.709370Z","shell.execute_reply":"2023-11-07T12:54:53.799610Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 41ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the predicted class to sentiment\nsentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\npredicted_sentiment = sentiment_labels[input_class[0]]\n\nprint(f\"Predicted Sentiment for the input text: {predicted_sentiment}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T12:54:57.899586Z","iopub.execute_input":"2023-11-07T12:54:57.899961Z","iopub.status.idle":"2023-11-07T12:54:57.905863Z","shell.execute_reply.started":"2023-11-07T12:54:57.899931Z","shell.execute_reply":"2023-11-07T12:54:57.904836Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Predicted Sentiment for the input text: Negative\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}